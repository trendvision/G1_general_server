{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CheckGraphic import CheckGraphicID\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pymongo\n",
    "import bson\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "from itertools import permutations\n",
    "from IPython.display import Image \n",
    "from IPython.core.display import Image, display\n",
    "username = \"tagger-admin\"\n",
    "password = \"tvaiadmin\"\n",
    "db_client = pymongo.MongoClient('104.198.62.226', username=username,\n",
    "                                password=password,\n",
    "                                authSource='tags',\n",
    "                                authMechanism='SCRAM-SHA-256', port=27017).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_client[\"tweets_pipeline_v2\"].find(\n",
    "                                           {\"status\":\"pipelined\",\n",
    "                                           \"source\":\"def\"},\n",
    "    no_cursor_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5f113253684654236514c9e8'), 'search_text': 'range resources \"market share\" 2020', 'exec_date': datetime.datetime(2020, 7, 17, 4, 57, 48, 13000), 'img_urls': 'https://www.sec.gov/Archives/edgar/data/315852/000130817918000145/lrrc047.jpg', 'TIME_FIELD_FOR_SORTING': datetime.datetime(2020, 7, 17, 4, 57, 48, 13000), 'source': 'def', 'img_type': 'graphic', 'tech_type': 'norm', 'status': 'pipelined', 'extracted_text': 'TOTAL PROVED RESERVES COSTS PER MCFE (BCFE) $2.19 15,262 $1.78 $1.68 12,072 9,892 2015 2016 2017 2015 2016 2017 DRILL BIT FINDING COSTS* PRODUCTION GROWTH PER SHARE (PER MCFE) (DEBT ADJUSTED) 14% $0.85 $0.36 4% $0.33 0% 2015 2016 2017 2015 2016 2017 * Excluding acquisitions RESERVE GROWTH PER SHARE (DEBT ADJUSTED) EBITDAX (IN MILLIONS) 24% $1,103 $897 $723 2015 2016 2017 2015 2016 2017 -6% -6%', 'bert_tags': [], 'industries_from_bert': ['Energy sources'], 'shifts_from_bert': [], 'trasher': [], 'pipelined_ts': datetime.datetime(2020, 7, 17, 5, 8, 35, 296000), 'aws_answer': [{'Score': 0.8006768226623535, 'Type': 'QUANTITY', 'Text': 'TOTAL', 'BeginOffset': 0, 'EndOffset': 5}, {'Score': 0.6140151023864746, 'Type': 'ORGANIZATION', 'Text': 'BCFE', 'BeginOffset': 38, 'EndOffset': 42}, {'Score': 0.9984563589096069, 'Type': 'QUANTITY', 'Text': '$2.19', 'BeginOffset': 44, 'EndOffset': 49}, {'Score': 0.5261922478675842, 'Type': 'QUANTITY', 'Text': '15,262', 'BeginOffset': 50, 'EndOffset': 56}, {'Score': 0.9974830150604248, 'Type': 'QUANTITY', 'Text': '$1.78', 'BeginOffset': 57, 'EndOffset': 62}, {'Score': 0.9588066339492798, 'Type': 'QUANTITY', 'Text': '$1.68 12,072 9,892', 'BeginOffset': 63, 'EndOffset': 81}, {'Score': 0.950095534324646, 'Type': 'DATE', 'Text': '2015', 'BeginOffset': 82, 'EndOffset': 86}, {'Score': 0.7653813362121582, 'Type': 'DATE', 'Text': '2016', 'BeginOffset': 87, 'EndOffset': 91}, {'Score': 0.6331862211227417, 'Type': 'DATE', 'Text': '2017', 'BeginOffset': 92, 'EndOffset': 96}, {'Score': 0.6968624591827393, 'Type': 'DATE', 'Text': '2015 2016 2017', 'BeginOffset': 97, 'EndOffset': 111}, {'Score': 0.9979934096336365, 'Type': 'QUANTITY', 'Text': '14%', 'BeginOffset': 192, 'EndOffset': 195}, {'Score': 0.9945762157440186, 'Type': 'QUANTITY', 'Text': '$0.85', 'BeginOffset': 196, 'EndOffset': 201}, {'Score': 0.9827249646186829, 'Type': 'QUANTITY', 'Text': '$0.36 4%', 'BeginOffset': 202, 'EndOffset': 210}, {'Score': 0.9459641575813293, 'Type': 'QUANTITY', 'Text': '$0.33 0%', 'BeginOffset': 211, 'EndOffset': 219}, {'Score': 0.9850777387619019, 'Type': 'DATE', 'Text': '2015', 'BeginOffset': 220, 'EndOffset': 224}, {'Score': 0.6422009468078613, 'Type': 'DATE', 'Text': '2016', 'BeginOffset': 225, 'EndOffset': 229}, {'Score': 0.6433588266372681, 'Type': 'DATE', 'Text': '2017', 'BeginOffset': 230, 'EndOffset': 234}, {'Score': 0.6483289003372192, 'Type': 'DATE', 'Text': '2015 2016', 'BeginOffset': 235, 'EndOffset': 244}, {'Score': 0.48733383417129517, 'Type': 'DATE', 'Text': '2017', 'BeginOffset': 245, 'EndOffset': 249}, {'Score': 0.9327555298805237, 'Type': 'ORGANIZATION', 'Text': 'EBITDAX', 'BeginOffset': 316, 'EndOffset': 323}, {'Score': 0.9988308548927307, 'Type': 'QUANTITY', 'Text': '24%', 'BeginOffset': 338, 'EndOffset': 341}, {'Score': 0.9980244040489197, 'Type': 'QUANTITY', 'Text': '$1,103', 'BeginOffset': 342, 'EndOffset': 348}, {'Score': 0.9914982914924622, 'Type': 'QUANTITY', 'Text': '$897', 'BeginOffset': 349, 'EndOffset': 353}, {'Score': 0.9821150302886963, 'Type': 'QUANTITY', 'Text': '$723', 'BeginOffset': 354, 'EndOffset': 358}, {'Score': 0.7941489219665527, 'Type': 'DATE', 'Text': '2015', 'BeginOffset': 359, 'EndOffset': 363}, {'Score': 0.8279891610145569, 'Type': 'DATE', 'Text': '2016', 'BeginOffset': 364, 'EndOffset': 368}, {'Score': 0.7087740302085876, 'Type': 'DATE', 'Text': '2017', 'BeginOffset': 369, 'EndOffset': 373}, {'Score': 0.7728880643844604, 'Type': 'DATE', 'Text': '2015', 'BeginOffset': 374, 'EndOffset': 378}, {'Score': 0.4888622760772705, 'Type': 'DATE', 'Text': '2016', 'BeginOffset': 379, 'EndOffset': 383}, {'Score': 0.44835364818573, 'Type': 'DATE', 'Text': '2017', 'BeginOffset': 384, 'EndOffset': 388}, {'Score': 0.8468390703201294, 'Type': 'QUANTITY', 'Text': '6%', 'BeginOffset': 390, 'EndOffset': 392}, {'Score': 0.9798572063446045, 'Type': 'QUANTITY', 'Text': '6%', 'BeginOffset': 394, 'EndOffset': 396}], 'entity_prepared': ['bce'], 'dhash': '161033e7d72b1818', 'entity_response_aws_2': [], 'entity_set': True, 'previous_source': 'google', 'previous_status': 'bd_search'}\n"
     ]
    }
   ],
   "source": [
    "for i in db:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in db_client[\"tweets_pipeline_v2\"].find({\"$or\": [{\"status\":\"pipelined\"},\n",
    "# #                                                            {\"status\":\"graphicone_feed\"}\n",
    "#                                                       ],\n",
    "#                                                        'source': 'sec',\n",
    "# #                                                    'approved_timestamp': {'$gte': end_date, '$lte': start_date},\n",
    "#                                                    }):\n",
    "#     print(i['_id'])\n",
    "#     print(i['entity_prepared']+i[\"bert_tags\"])    \n",
    "#     CheckGraphicID(i['_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image\n",
    "# url = 'http://www.example.com/my_image_is_not_your_image.png'\n",
    "# image = Image.open(urllib.request.urlopen(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeFilter(size):\n",
    "    width, height = image.size\n",
    "    if width < 350 or height < 350:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_size(_id):\n",
    "    db_client[\"tweets_pipeline_v2\"].update_one({\"_id\":bson.ObjectId(_id)},\n",
    "                                               {\"$set\":{\n",
    "                                                   'status': \"small_size\",\n",
    "                                                       }})      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = db_client[\"tweets_pipeline_v2\"].find(\n",
    "                                           {\"status\":\"pipelined\",\n",
    "                                           \"source\":\"def\"},\n",
    "    no_cursor_timeout=True)\n",
    "\n",
    "db.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2104/2104 [09:32<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(db, total = db.count()):\n",
    "    try:\n",
    "        image = Image.open(urllib.request.urlopen(i['img_urls']))\n",
    "        if not sizeFilter(image.size):\n",
    "            try:\n",
    "                small_size(str(i['_id']))\n",
    "    #             CheckGraphicID(i['_id'])\n",
    "            except Exception as err:\n",
    "                pass\n",
    "    except Exception as err:\n",
    "        pass\n",
    "\n",
    "             \n",
    "    \n",
    "#     try:\n",
    "#         image = Image.open(urllib.request.urlopen(i['img_urls']))\n",
    "#         if not sizeFilter(image.size):\n",
    "#             print(image.size)\n",
    "#             print(i['_id'])\n",
    "#             print(i[\"bert_tags\"])\n",
    "#     #         print(i['entity_prepared']+i[\"bert_tags\"])    \n",
    "#             CheckGraphicID(i['_id'])\n",
    "#     except Exception as err:\n",
    "#         pass\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2281"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_client[\"tweets_pipeline_v2\"].find({'status': \"small_size\"}, no_cursor_timeout=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = db_client[\"tweets_pipeline_v2\"].find_one({\"_id\":bson.ObjectId(str(\"5f1385be3e25deec88b6287e\"))})\n",
    "Image.open(urllib.request.urlopen(a['img_urls'])).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in db_client[\"tweets_pipeline_v2\"].find({\"$or\": [{\"status\":\"trasher\"},\n",
    "# #                                                            {\"status\":\"graphicone_feed\"}\n",
    "#                                                       ],\n",
    "#                                                        'source': 'sec',\n",
    "# #                                                    'approved_timestamp': {'$gte': end_date, '$lte': start_date},\n",
    "#                                                    }):\n",
    "    \n",
    "\n",
    "#     i['img_urls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_client[\"tweets_pipeline_v2\"].find(\n",
    "                                           {\"status\":\"pipelined\",\n",
    "                                           \"source\":\"def\"},\n",
    "    no_cursor_timeout=True)\n",
    "\n",
    "db.count()\n",
    "\n",
    "\n",
    "tagsCollector = []\n",
    "for i in db:\n",
    "    tags = i[\"entity_prepared\"]+i[\"bert_tags\"]\n",
    "    tags = list(set(tags))\n",
    "    tagsCollector += tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict(Counter(tagsCollector).most_common()), orient='index').to_excel(\"bd_search_graphs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_client[\"tweets_pipeline_v2\"].find(\n",
    "                                        {\n",
    "        \"$or\": [{\"status\":\"graphicone_search\"}, {\"status\":\"graphicone_feed\"}],\n",
    "                                        },\n",
    "    no_cursor_timeout=True)\n",
    "\n",
    "db.count()\n",
    "\n",
    "\n",
    "tagsCollector = []\n",
    "for i in db:\n",
    "    tagsCollector += i[\"grafeed_confirmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict(Counter(tagsCollector).most_common()), orient='index').to_excel(\"all_graphs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'employment', 'labor'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set([\"employment\", \"labor\"])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set([\"employment\", \"aasdsad\", \"asdasdsa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.issubset(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "(9, 'Client timeout: socket=30000 total=1000 iterations=1 lastNode=35.228.136.58:3000', 'src/main/client/get.c', 113, False)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-92e13b43290c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_as_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ids_to_validate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtags_by_tag_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_as_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m: (9, 'Client timeout: socket=30000 total=1000 iterations=1 lastNode=35.228.136.58:3000', 'src/main/client/get.c', 113, False)"
     ]
    }
   ],
   "source": [
    "import aerospike\n",
    "config = {\n",
    "    'hosts': [('35.228.136.58', 3000)]\n",
    "}\n",
    "client = aerospike.client(config).connect()\n",
    "data_as_key = (\"ids_to_validate\", \"data\", \"data\")\n",
    "\n",
    "tags_by_tag_old = client.get(data_as_key)[-1]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictImplementation(tagsList):\n",
    "    result = []\n",
    "    for tag in tagsList:\n",
    "        if tag.lower() in tags_by_tag_old and tags_by_tag_old[tag.lower()] != [0]:\n",
    "            result += tags_by_tag_old[tag.lower()]\n",
    "        if tag.lower() not in tags_by_tag_old:\n",
    "            result.append(tag.lower())\n",
    "    return list(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = []\n",
    "collector_sub = []\n",
    "for i in db_client[\"tweets_pipeline_v2\"].find({\"$or\": [{\"status\":\"graphicone_search\"},\n",
    "                                                       {\"status\":\"graphicone_feed\"}],\n",
    "                                               }):\n",
    "    if \"grafeed_confirmed\" in i:\n",
    "        analyst = set(i[\"grafeed_confirmed\"])\n",
    "        collector += dictImplementation(analyst)\n",
    "#         if set([\"employment\", \"labor\"]).issubset(analyst):\n",
    "#             collector_sub += analyst\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict(Counter(collector)), orient=\"index\").to_excel(\"anzelika_total.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(dict(Counter(collector_sub)), orient=\"index\").to_excel(\"anzelika_subset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv(\"worldcities.csv\")\n",
    "cities = cities[(cities[\"population\"]/1000000)>=1][\"city_ascii\"]\n",
    "cities_set = set([city.lower() for city in cities.values])\n",
    "\n",
    "tags_dictionary_set_without_cities = tags_dictionary_set_without_countries - cities_set\n",
    "len(tags_dictionary_set_without_cities)\n",
    "\n",
    "# cities\n",
    "# countries_set = \n",
    "# print(len(countries_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"countries-data.csv\")[\"Name\"]\n",
    "countries_set = set([country.lower() for country in countries.values])\n",
    "print(len(countries_set))\n",
    "\n",
    "tags_dictionary_set_without_countries = tags_dictionary_set_without_securities - countries_set\n",
    "len(tags_dictionary_set_without_countries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
